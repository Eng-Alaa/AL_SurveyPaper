{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2535896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae45e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_uncertainty_LeastConfident(X, model):\n",
    "    # Get predicted probabilities for each class\n",
    "    predicted_probs = model.predict_proba(X)    \n",
    "    # Calculate uncertainty scores as the least confident probability\n",
    "    least_confident = 1 - np.max(predicted_probs, axis=1)    \n",
    "    return least_confident\n",
    "\n",
    "def calculate_uncertainty_SmallestMargin(X, model):\n",
    "    # Get predicted probabilities for each class\n",
    "    predicted_probs = model.predict_proba(X)    \n",
    "    # Sort the predicted probabilities in descending order\n",
    "    sorted_probs = np.sort(predicted_probs, axis=1)[:, ::-1]    \n",
    "    # Calculate uncertainty scores as the difference between the top two probabilities\n",
    "    smallest_margin = sorted_probs[:, 0] - sorted_probs[:, 1]    \n",
    "    return smallest_margin\n",
    "\n",
    "def calculate_uncertainty_Entropy(X, model):\n",
    "    # Get predicted probabilities for each class\n",
    "    predicted_probs = model.predict_proba(X)    \n",
    "    # Check for zero probabilities and replace them with a small value\n",
    "    predicted_probs[predicted_probs == 0] = 1e-10\n",
    "    # Calculate uncertainty scores using the entropy\n",
    "    entropy = -np.sum(predicted_probs * np.log2(predicted_probs), axis=1)\n",
    "    # Handle the case of uniform probabilities\n",
    "    entropy[np.isnan(entropy)] = 0    \n",
    "    return entropy\n",
    "\n",
    "def select_uncertain_samples_LC(X, model, n_samples=1):\n",
    "    uncertainty_scores=calculate_uncertainty_LeastConfident(X, model)   \n",
    "    # Select the indices of the most uncertain samples\n",
    "    uncertain_indices = np.argsort(uncertainty_scores)[-n_samples:]    \n",
    "    return uncertain_indices,uncertainty_scores\n",
    "\n",
    "def select_uncertain_samples_SM(X, model, n_samples=1):\n",
    "    uncertainty_scores=calculate_uncertainty_SmallestMargin(X, model)   \n",
    "    # Select the indices of the most uncertain samples\n",
    "    #uncertain_indices = np.argsort(uncertainty_scores)[:n_samples]    \n",
    "    uncertain_indices = np.argsort(uncertainty_scores)[::-1][-n_samples:]\n",
    "    #np.where(uncertainty_scores == np.min(uncertainty_scores))    \n",
    "    return uncertain_indices ,uncertainty_scores\n",
    "\n",
    "def select_uncertain_samples_Entropy(X, model, n_samples=1):\n",
    "    uncertainty_scores=calculate_uncertainty_Entropy(X, model_Entropy)   \n",
    "    # Select the indices of the most uncertain samples\n",
    "    uncertain_indices = np.argsort(uncertainty_scores)[-n_samples:]    \n",
    "    np.where(uncertainty_scores == np.max(uncertainty_scores))    \n",
    "    return uncertain_indices,uncertainty_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5c8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data[:, :2], iris.target\n",
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Entropy = LogisticRegression()\n",
    "model_LC = LogisticRegression()\n",
    "model_SM = LogisticRegression()\n",
    "# Select initial labeled samples randomly\n",
    "labeled_indices = np.random.choice(X.shape[0], size=5, replace=False)\n",
    "unlabeled_indices = np.setdiff1d(np.arange(X.shape[0]), labeled_indices)\n",
    "\n",
    "labeled_indices_Entropy=labeled_indices\n",
    "labeled_indices_LC=labeled_indices\n",
    "labeled_indices_SM=labeled_indices\n",
    "\n",
    "unlabeled_indices_Entropy=unlabeled_indices\n",
    "unlabeled_indices_LC=unlabeled_indices\n",
    "unlabeled_indices_SM=unlabeled_indices\n",
    "# Start the active learning loop\n",
    "n_iterations = 5\n",
    "n_samples_per_iteration = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
